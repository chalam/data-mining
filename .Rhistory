library(tm)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
doc <- readLines("SOTU 2015.txt")
doc <- readLines("~/project/data-mining//SOTU 2015.txt")
length(doc)
length(doc)
head(doc)
tail(doc)
doc.vec <- VectorSource(doc)
doc.corpus <- Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"), lazy=TRUE)
doc.corpus <- tm_map(doc.corpus, stemDocument, lazy=TRUE)
inspect(doc.corpus)[1:2]
inspect(doc.corpus[3])
wordcloud(doc.corpus, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- Corpus(doc.vec)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"), lazy=TRUE)
wordcloud(doc.corpus, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
doc <- readLines("~/project/data-mining//SOTU.txt")
doc <- readLines("~/project/data-mining//SOTU_Small.txt")
length(doc)
head(doc)
tail(doc)
doc.vec <- VectorSource(doc)
doc.corpus <- Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"), lazy=TRUE)
# doc.corpus <- tm_map(doc.corpus, removeWords, c("nytimes", "2014"))
doc.corpus <- tm_map(doc.corpus, stemDocument, lazy=TRUE)
inspect(doc.corpus[3])
wordcloud(doc.corpus, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
doc.tdm <- TermDocumentMatrix (doc.corpus) #Creates a TDM
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"))
doc.corpus <- tm_map(doc.corpus, stemDocument)
inspect(doc.corpus[1])
wordcloud(doc.corpus, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
doc.tdm <- TermDocumentMatrix (doc.corpus) #Creates a TDM
doc.corpus <- Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"))
doc.corpus <- tm_map(doc.corpus, stemDocument)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
wordcloud(doc.corpus, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
setwd("~/project/data-mining")
doc <- readLines("SOTU_Small.txt")
length(doc)
head(doc)
tail(doc)
doc.vec <- VectorSource(doc)
doc.corpus <- Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"))
doc.corpus <- tm_map(doc.corpus, stemDocument)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[1])
doc.corpus <- tm_map(doc.corpus, PlainTextDocument)
inspect(doc.corpus[1])
wordcloud(doc.corpus, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
doc <- readLines("SOTU 2015.txt")
length(doc)
head(doc)
tail(doc)
doc.vec <- VectorSource(doc)
doc.corpus <- Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- Corpus(doc.vec)
doc.corpus <- tm_map(doc.corpus, tolower)
doc <- readLines("SOTU_Small.txt")
length(doc)
head(doc)
tail(doc)
doc.vec <- VectorSource(doc)
doc.corpus <- Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"))
doc.corpus <- tm_map(doc.corpus, stemDocument)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
doc.corpus <- tm_map(doc.corpus, PlainTextDocument)
inspect(doc.corpus[1])
wordcloud(doc.corpus, scale=c(5,0.5), max.words=1, random.order=FALSE, rot.per=0.1, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
doc.tdm <- TermDocumentMatrix (doc.corpus) #Creates a TDM
doc.tdm.mat <- as.matrix(doc.tdm) #Convert this into a matrix format
doc.tdm.vec = sort(rowSums(doc.tdm.mat), decreasing = TRUE) #Gives you the frequencies for every word
Summary(doc.tdm.mat)
Summary(doc.tdm.vec)
summary(doc.tdm.vec)
doc.tdm
doc.dtm <- DocumentTermMatrix(doc.corpus)
inspect(doc.dtm[1])
inspect(doc.dtm[1],[1])
inspect(doc.dtm[1],[1])
inspect(doc.dtm[1,1])
findFreqTerms(doc.tdm, 2000)
findFreqTerms(doc.tdm, 2)
findAssocs(TDM, "thank", 0.8) #associations between words for thank
findAssocs(doc.tdm, "thank", 0.8) #associations between words for thank
doc.tdm.comm = removeSparseTerms(doc.tdm, 0.1)
doc.tdm.common = removeSparseTerms(doc.tdm, 0.1)
dim(doc.tdm)
dim(doc.tdm.common)
library(slam)
doc.tdm.dense <- as.matrix(doc.tdm.common)
object.size(doc.tdm.common)
object.size(doc.tdm.dense)
palette <- brewer.pal(9,"BuGn")[-(1:4)]
wordcloud(rownames(doc.tdm.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
doc <- readLines("SOTU_Small.txt")
length(doc)
head(doc)
tail(doc)
doc.vec <- VectorSource(doc)
doc.corpus <- Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, tolower)
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"))
doc.corpus <- tm_map(doc.corpus, stemDocument)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
doc.corpus <- tm_map(doc.corpus, PlainTextDocument)
wordcloud(doc.corpus, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
doc.dtm <- DocumentTermMatrix(doc.corpus)
inspect(doc.dtm[1,1])
findFreqTerms(doc.tdm, 2) #most frequently occurring terms
findAssocs(doc.tdm, "thank", 0.8) #associations between words for thank
doc.tdm.common = removeSparseTerms(doc.tdm, 0.1)
dim(doc.tdm)
dim(doc.tdm.common)
doc.tdm.dense <- as.matrix(doc.tdm.common)
object.size(doc.tdm.common)
object.size(doc.tdm.dense)
palette <- brewer.pal(9,"BuGn")[-(1:4)]
wordcloud(rownames(doc.tdm.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
head(doc)
summary(doc.corpus)
inspect(doc.corpus[1])
inspect(doc.dtm[1,1])
inspect(doc.dtm)
findAssocs(doc.tdm, "lamy", 0.8) #associations between words for thank
findAssocs(doc.tdm, "thank", 0.8) #associations between words for thank
findAssocs(doc.tdm, "vice", 0.8) #associations between words for thank
findAssocs(doc.tdm, "vice", 0.1) #associations between words for thank
findAssocs(doc.tdm, "thank", 0.1) #associations between words for thank
doc.tdm.common = removeSparseTerms(doc.tdm, 0.1)
dim(doc.tdm)
dim(doc.tdm.common)
doc.tdm.dense <- as.matrix(doc.tdm.common)
object.size(doc.tdm.common)
palette <- brewer.pal(9,"BuGn")[-(1:4)]
doc.tdm.dense <- as.matrix(doc.tdm.common)
View(doc.tdm.dense)
View(doc.tdm.dense)
View(doc.tdm.mat)
doc.tdm.common = removeSparseTerms(doc.tdm, 0.1)
doc.tdm
inspect(doc.tdm)
doc.dtm <- DocumentTermMatrix(doc.corpus)
inspect(doc.dtm)
findFreqTerms(doc.tdm, 2) #most frequently occurring terms
findFreqTerms(doc.tdm, 1) #most frequently occurring terms
findFreqTerms(doc.tdm, 2) #most frequently occurring terms
inspect(doc.dtm)
doc.tdm.common = doc.tdm)
doc.tdm.common = doc.tdm
doc.tdm.dense <- as.matrix(doc.tdm.common)
object.size(doc.tdm.common)
object.size(doc.tdm.dense)
palette <- brewer.pal(9,"BuGn")[-(1:4)]
wordcloud(rownames(doc.tdm.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
inspect(doc.tdm)
doc.tdm.common = doc.tdm
inspect(doc.tdm.common)
inspect(doc.tdm)
inspect(doc.corpus[1])
doc.tdm <- TermDocumentMatrix(doc.corpus)
findFreqTerms(doc.tdm, 2) #most frequently occurring terms
findAssocs(doc.tdm, "thank", 0.1) #associations between words for thank
doc.tdm.common = removeSparseTerms(doc.tdm, 0.1)
inspect(doc.tdm)
inspect(doc.tdm.common)
doc.tdm.dense <- as.matrix(doc.tdm.common)
object.size(doc.tdm.common)
object.size(doc.tdm.dense)
palette <- brewer.pal(9,"BuGn")[-(1:4)]
wordcloud(rownames(doc.tdm.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
wordcloud(rownames(doc.tdm.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
wordcloud(rownames(doc.tdm.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
head(doc.tdm.dense)
library(ggplot2)
install.library(ggplot)
install.packages("ggplot2")
library(ggplot2)
ggplot(doc.tdm.dense, aes(x = Docs, y = Terms, fill = log10(count)))
head(doc.tdm.dense)
TEXTFILE = "shakespeare.txt"
if (!file.exists(TEXTFILE)) {
download.file("http://www.gutenberg.org/cache/epub/100/pg100.txt", destfile = TEXTFILE)
}
length(shakespeare)
shakespeare = readLines(TEXTFILE)
length(shakespeare)
doc <- readLines("shakespeare.txt")
length(doc)
head(doc)
tail(doc)
shakespeare = shakespeare[-(1:173)]
shakespeare = shakespeare[-(124195:length(shakespeare))]
shakespeare = paste(shakespeare, collapse = " ")
nchar(shakespeare)
shakespeare = strsplit(shakespeare, "<<[^>]*>>")[[1]]
length(shakespeare)
(dramatis.personae <- grep("Dramatis Personae", shakespeare, ignore.case = TRUE)) # Person info
length(shakespeare)
shakespeare = shakespeare[-dramatis.personae]
length(shakespeare)
doc.vec = VectorSource(shakespeare)
doc.corpus = Corpus(doc.vec)
summary(doc.corpus)
doc.corpus <- tm_map(doc.corpus, content_transformer(tolower))
doc.corpus <- tm_map(doc.corpus, removeWords, stopwords("english"))
doc.corpus <- tm_map(doc.corpus, removeNumbers)
doc.corpus <- tm_map(doc.corpus, removePunctuation)
library(SnowballC)
doc.corpus <- tm_map(doc.corpus, stemDocument)
doc.corpus <- tm_map(doc.corpus, stripWhitespace)
inspect(doc.corpus[8])
TDM <- TermDocumentMatrix(doc.corpus)
TDM
inspect(TDM[1:10,1:10])
DTM <- DocumentTermMatrix(doc.corpus)
DTM
inspect(DTM[1:10,1:10])
findFreqTerms(TDM, 2000)
findAssocs(TDM, "love", 0.8)
TDM.common = removeSparseTerms(TDM, 0.1)
dim(TDM)
dim(TDM.common)
inspect(TDM.common[1:10,1:10])
library(slam)
TDM.dense <- as.matrix(TDM.common)
TDM.dense
object.size(TDM.common)
object.size(TDM.dense)
library(wordcloud)
library(RColorBrewer)
palette <- brewer.pal(9,"BuGn")[-(1:4)]
wordcloud(rownames(doc.tdm.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
wordcloud(rownames(TDM.dense), rowSums(doc.tdm.dense), min.freq = 1, color = palette)
wordcloud(rownames(TDM.dense), rowSums(TDM.dense), min.freq = 1, color = palette)
library(reshape2)
TDM.dense.clean = melt(TDM.dense, value.name = "count")
head(TDM.dense.clean)
library(ggplot2)
ggplot(TDM.dense.clean, aes(x = Docs, y = Terms, fill = log10(count))) +
+     geom_tile(colour = "white") +
+     scale_fill_gradient(high="#FF0000" , low="#FFFFFF")+
+     ylab("") +
+     theme(panel.background = element_blank()) +
+     theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
library(arules)
tr<-read.transactions("transactions.txt",format="basket",sep=",")
tr<-read.transactions("transactions.txt",format="basket",sep=",")
inspect(tr)
image(tr)
itemFrequencyPlot(tr, support = 0.1)
length(tr)
rules <- apriori(tr, parameter= list(supp=0.5, conf=0.5))
inspect(rules)
tr<-read.transactions("transactions.txt",format="basket",sep=",")
inspect(tr)
image(tr)
itemFrequencyPlot(tr, support = 0.1)
length(tr)
rules <- apriori(tr, parameter= list(supp=0.5, conf=0.5))
inspect(rules)
summary(rules)
length(rules)
rules
length(rules)
inspect(rules)
f <- eclat(tr, parameter = list(support = 0, tidLists = TRUE))
f <- eclat(tr, parameter = list(support = 0.5, tidLists = TRUE))
dim(tidLists(f))
as(tidLists(f), "list")
image(tidLists(f))
inspect(f)
install.library("arulesSequences")
install.packages("arulesSequences")
install.packages("cluster")
install.packages("arulesNBMiner")
install.packages("arulesViz")
library(arulesViz)
plot(rules)
plot(rules, method="paracoord", control=list(reorder=TRUE))
